# La Regresi√≥n Log√≠stica como Red Neuronal explicado de forma sencilla

## 1. ¬øQu√© se hace en la Regresi√≥n Log√≠stica?
En la regresi√≥n log√≠stica, queremos ajustar unos par√°metros para que nuestro modelo haga predicciones lo m√°s precisas posible. Imagina que est√°s ajustando los botones de un control para que el televisor muestre la mejor imagen. En este caso, los botones son nuestros par√°metros (llamados pesos y sesgo), y queremos encontrar el ajuste perfecto.

## 2. ¬øC√≥mo funcionan los Gr√°ficos de C√°luclo?
Piensa en un gr√°fico de c√°lculo como un diagrama de flujo o un mapa que muestra c√≥mo se calculan las cosas paso a paso:

- **Primero:** Calculamos un valor intermedio (llamado ùëç) usando nuestros par√°metros y datos de entrada.
- **Luego:** Usamos ese valor intermedio para obtener una predicci√≥n (llamada $\hat Y$).
- **Finalmente:** Comparamos la predicci√≥n con la respuesta correcta y calculamos cu√°nto nos equivocamos (esto es la p√©rdida).

## 3. ¬øC√≥mo mejoramos el modelo?
Queremos ajustar nuestros par√°metros (botones) para reducir ese error. Aqu√≠ es donde entran las derivadas, que nos dicen c√≥mo cambiar cada par√°metro para mejorar el modelo.

## 4. Pasos simples para Actualizar los Par√°metros
**1. Calcula el error (Funci√≥n de Coste):** Primero, calcula cu√°nto se equivoc√≥ el modelo. Esto es como ver cu√°nto te desviaste del objetivo.

**2. Calcula c√≥mo cambiar los par√°metros (Descenso de Gradiente):** Determina c√≥mo ajustar cada par√°metro para reducir el error.

**3. Actualiza los Par√°metros:** Ajusta cada par√°metro un poco basado en el c√°lculo anterior.

### Ejemplo Pr√°ctico
1. Predicci√≥n: Supongamos que tienes dos caracter√≠sticas (como el tama√±o y el color de una manzana) y los par√°metros que quieres ajustar son como la sensibilidad del sensor a esas caracter√≠sticas.

2. Comparar: Tu modelo predice si la manzana es roja o verde, pero la respuesta correcta es verde. El modelo se equivoc√≥.

3. Ajustar:
    - Mira cu√°nto te equivocaste.
    - Ajusta la sensibilidad del sensor (par√°metros) para que sea m√°s preciso en la pr√≥xima predicci√≥n.

## 5. Implementaci√≥n en el C√≥digo:
En la pr√°ctica, estos c√°lculos se hacen autom√°ticamente usando herramientas de programaci√≥n. Solo necesitas saber que est√°s ajustando los par√°metros bas√°ndote en el error del modelo.

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p>

# La Regresi√≥n Log√≠stica como Red Neuronal explicado de m√°s extensa

## 1. Introducci√≥n a la Regresi√≥n Log√≠stica

La regresi√≥n log√≠stica es un algoritmo de aprendizaje supervisado utilizado para problemas de clasificaci√≥n binaria, donde las etiquetas de salida $Y$ son 0 o 1. Por ejemplo, si queremos clasificar im√°genes como "gato" o "no gato", el modelo debe predecir la probabilidad de que la imagen sea de un gato.

El objetivo de la regresi√≥n log√≠stica es predecir la probabilidad de que $Y$ sea igual a 1 dado un vector de caracter√≠sticas de entrada $X$. Esta probabilidad se denota como $\hat Y$, donde:

$\hat Y = P(Y = 1 ‚à£ X)$

El modelo de regresi√≥n log√≠stica se define como:

$\hat Y = \sigma(W^{t} X + b)$

Donde:

- $X$ es el vector de caracter√≠sticas de entrada.
- $W$ es el vector de pesos que asigna importancia a cada caracter√≠stica.
- $b$ es el sesgo o intercepto, que permite ajustar el modelo.
- $(W^{t} X + b)$ es la combinaci√≥n lineal de las caracter√≠sticas y los par√°metros.
- ùúé(‚ãÖ) es la funci√≥n sigmoide, que convierte el resultado de la combinaci√≥n lineal en una probabilidad entre 0 y 1.


### Funci√≥n Sigmoide

La funci√≥n sigmoide es una funci√≥n matem√°tica que toma un n√∫mero real $z$ y lo transforma en un valor entre 0 y 1. Es ideal para modelar probabilidades, ya que garantiza que el valor predicho siempre est√© en este rango. Su f√≥rmula es:

$\sigma (z) = \frac{1}{1+e^{-z}}$

Donde $e$ es la base del logaritmo natural (aproximadamente 2.718).

La funci√≥n sigmoide tiene las siguientes propiedades:
- Cuando $z$ es grande, $\sigma (z)$ se aproxima a 1. 
- Cuando $z$ es peque√±o (negativo), $\sigma (z)$ se aproxima a 0.
-  Cuando $z = 0$, $\sigma (z) = 0.5$ es decir, una probabilidad del 50%.


## 2. Funci√≥n de coste de regresi√≥n log√≠stica 

### Funci√≥n de P√©rdida

Esta funci√≥n mide qu√© tan bien est√°n funcionando los par√°metros $W$ (pesos) y $b$ (sesgo) en el conjunto de entrenamiento completo.

Para ello, utilizamos una funci√≥n de p√©rdida que mide como de bien las predicciones $\hat Y$ se alinean con los valores reales $Y$ para un ejemplo espec√≠fico. 

Su f√≥rmula es la siguiente:

$L (\hat Y, Y) = \lfloor Y log(\hat Y) + (1 - Y) log(1 - \hat Y) \rfloor$

- Cuando $Y = 1$: La p√©rdida es $-log(\hat Y)$, lo que incentiva a que $\hat Y$ sea lo m√°s cercano a 1 posible.

- Cuando $Y = 0$: La p√©rdida es $-log(1 - \hat Y)$, lo que incentiva a que $\hat Y$ sea lo m√°s cercano a 1 posible.


### Funci√≥n de Coste $J(W, b)$

Mientras que la funci√≥n de p√©rdida mide el error en un solo ejemplo, la funci√≥n de coste mide el error promedio en todo el conjunto de entrenamiento.

Para el conjunto completo de ejemplos de entrenamiento, la funci√≥n de coste total $J(W,b)$ se calcula como el promedio de las p√©rdidas individuales de cada ejemplo:

$J(W,b) = - \frac{1}{m}  \sum_{i=1}^{m}\left [Y^{(i)} log(\hat Y^{(i)}) + (1 - Y^{(i)}) log(1 - \hat Y^{(i)})\right ]$

Donde $m$ es el n√∫mero total de ejemplos en el entrenamiento.


## 3. Descenso de gradiente

El descenso de gradiente se emplea el objetivo de encontrar los valores de $W$ y $b$ que minimicen la funci√≥n de costo $J(W, b)$. Es decir, encuentra los par√°metros que hacen que las perdicciones del modelo sean lo m√°s precisas posibles. 

Para ello, se empieza con valores iniciales para $W$ y $b$ (que pueden ser cero, por ejemplo) y se actualizan iterativamente tomando peque√±os pasos en la direcci√≥n que reduce el valor de la funci√≥n de costo.

### Convexidad de la Funci√≥n de Costo

La funci√≥n de costo en la regresi√≥n log√≠stica es convexa, lo que significa que tiene la forma de un cuenco.

Esto asegura que siempre habr√° un √∫nico m√≠nimo global (el punto m√°s bajo del cuenco). Por lo tanto, el algoritmo de descenso por gradiente encontrar√° este m√≠nimo global sin importar el punto de partida inicial.
